{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef31ee8f-0474-4d7b-8ca2-71a3879c221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/home/llajan/OPT-175B-HF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835d4bf-99aa-4b26-9ff7-53904a1b0709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import OPTConfig\n",
    "from accelerate import init_empty_weights, dispatch_model, infer_auto_device_map, load_checkpoint_in_model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load config\n",
    "with open(os.path.join(weights_path, 'config.json'), 'r') as f:\n",
    "    config = json.load(f)\n",
    "config[\"_name_or_path\"] = weights_path\n",
    "config = OPTConfig(**config)\n",
    "\n",
    "# Initializes an empty shell with the model. This is instant and does not take any RAM.\n",
    "with init_empty_weights():\n",
    "    model = AutoModelForCausalLM.from_config(config)\n",
    "# Initialize the model under the previous context manager breaks the tied weights.\n",
    "model.tie_weights()\n",
    "\n",
    "# Infer device map automatically\n",
    "device_map = infer_auto_device_map(model.model, no_split_module_classes=[\"OPTDecoderLayer\"], dtype='float16')\n",
    "\n",
    "# Load weights\n",
    "load_checkpoint_in_model(\n",
    "    model.model, \n",
    "    weights_path, \n",
    "    device_map=device_map, \n",
    "    offload_folder=None, \n",
    "    dtype='float16', \n",
    "    offload_state_dict=True\n",
    ")\n",
    "model.tie_weights()\n",
    "\n",
    "# Without this part, torch complains about tensors being in different devices\n",
    "full_model_device_map = {f\"model.{k}\": v for k, v in device_map.items()}\n",
    "full_model_device_map[\"lm_head\"] = 0\n",
    "dispatch_model(model, device_map=full_model_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "108726fe-31b8-4cea-b88b-548c41dc45a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Although Federer is a better player than Nadal, the Spaniard has a better record against the Swiss. The two have met on 14 occasions, with Nadal winning 10 of those matches.\n",
      "\n",
      "The two have met in the final of the French Open on three occasions, with Nadal winning all three of those matches.\n",
      "\n",
      "The two have met in the final of the US Open on two occasions, with Nadal winning both of those matches.\n",
      "\n",
      "The two have met in\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/opt-30b')\n",
    "inputs = tokenizer(\"Although Federer is a better player than Nadal,\", return_tensors=\"pt\")\n",
    "# inputs = tokenizer(\"Facebook changed it's company name because\", return_tensors=\"pt\")\n",
    "# inputs = tokenizer(\"The key steps to making coffee are\\n\", return_tensors=\"pt\")\n",
    "\n",
    "output = model.generate(inputs[\"input_ids\"].to(0), max_length=100, do_sample=True)\n",
    "\n",
    "print(tokenizer.decode(output[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
